---
layout: article
title: Hackathons
aside:
  toc: true
---

## AstroxML Hackathon 2024

<center>
<span style="font-size: 24px;">
Freedom Trail of Code: Boston Astrophysics x Machine Learning Hackathon 2024
</span>
</center>
<img src="images/astro-ml_hackathon.png" align="left" style="max-width:5990px;width:100%" hspace="10" vspace="10">

[Registration](https://docs.google.com/forms/d/e/1FAIpQLScQA5zPIQymCimv89YVnOSzFRi8FI17aHqX9yxtWLZXnmRwag/viewform){:.button.button--outline-primary.button--pill.button--lg} [About](#about){:.button.button--outline-primary.button--pill.button--lg} [Projects](#projects){:.button.button--outline-primary.button--pill.button--lg} [Resources](#resources){:.button.button--outline-primary.button--pill.button--lg}[Organizing Committee](#organizing-committee){:.button.button--outline-primary.button--pill.button--lg}  

### About 
The Institute for Artificial Intelligence and Fundamental Interactions (IAIFI) is enabling physics discoveries and advancing foundational AI through the development of novel AI approaches that incorporate first principles, best practices, and domain knowledge from fundamental physics. Participants in the AstroxML hackathon, organized by IAIFI and collaborators, will team up to tackle real-world astrophysical problems leveraging machine learning. We welcome both less experienced participants and machine learning gurus looking for interesting problems to solve with AI.  We promise all an exciting week of caffeine-fueled coding sessions. Lunch and refreshments will be provided.

* **January 22â€“24, 2024**
* **MIT Stata Center**
* **[Register by December 15, 2023](https://docs.google.com/forms/d/e/1FAIpQLScQA5zPIQymCimv89YVnOSzFRi8FI17aHqX9yxtWLZXnmRwag/viewform)** 

### Projects
Details for the projects will be provided soon. Topics for the projects will include: 
* Generative everything: Understand the generative model paradigm, and learn how to train diffusion generative models for a dataset of your choosing. Explore their utility for emulation, likelihood evaluation, posterior estimation, and anomaly detection. 
* Simulation-based everything: Build up the tools necessary to do simulation-based (or likelihood-free) inference. If you have a forward model or simulator for your data and are sick of losing information by using summary statistics, this may be for you!
* Multimodal everything: Understand how to train joint embeddings across or within modalities. Examples: (1) images + spectra + light curves, or (2) the same object observed by different instruments. Explore the structure of joint embeddings and how to use them for various downstream tasks. Bring your own multi-modal datasets!
* Anomaly detection: Extract informative features and build lower-dimensional representations of your dataset to find the rarest and strangest instances! We'll hack models for zero-shot and few-shot learning.
* Super resolution everything: Enhancing the resolution of simulations that are too expensive to run at high resolution, for example hydrodynamical simulations of galaxy formation.

### Resources
To make the most out of the hack, we recommend those unexperienced with machine learning to review the awesome [UvA Deep Learning tutorials](https://uvadlc-notebooks.readthedocs.io/en/latest/index.html).
* Firstly, familiarize yourself with the most popular machine learning libraries in python: PyTorch ([tutorial link](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html)) and Jax ([tutorial link](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html)). If you have never worked on ML, PyTorch might have a kinder learning curve, although Jax can be extremely useful and fast for scientific problems. [Check this out](https://kidger.site/thoughts/torch2jax/) to transition from PyTorch to Jax.
* Follow Tutorials 3 and 4 for an overview of training machine learning models in either of the frameworks.
* If you are interested in the "Generative everything" hack project, follow the [deep auto encoders](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html) and [normalising flows](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html) tutorials.
* For "simulation-based everything" check out [this tutorial](https://github.com/smsharma/sbi-lecture-mit/blob/main/tutorial.ipynb)

If you are looking for inspiration on interesting projects at the intersection of machine learning and astrophysics check out these resources: 
* [ML in cosmology](https://github.com/georgestein/ml-in-cosmology)
* [Simulation-based inference in cosmology & astrophysics](https://github.com/smsharma/awesome-neural-sbi#cosmology-astrophysics-and-astronomy)

### Organizing Committee

* Riccardo Arcodia ([rarcodia@mit.edu](mailto:rarcodia@mit.edu))
* Dillon Brout ([dbrout@bu.edu](mailto:dbrout@bu.edu))
* Carolina Cuesta-Lazaro ([cuestalz@mit.edu](mailto:cuestalz@mit.edu))
* Alex Gagliano ([gaglian2@mit.edu](mailto:gaglian2@mit.edu))
* Siddharth Mishra-Sharma ([smsharma@mit.edu](mailto:smsharma@mit.edu))
* Daniel Muthukrishna ([danmuth@mit.edu](mailto:danmuth@mit.edu))
* Yueying Ni ([yueying.ni@cfa.harvard.edu](mailto:yueying.ni@cfa.harvard.edu))

Contact [iaifi@mit.edu](mailto:iaifi@mit.edu) or any of the organizers with questions.
