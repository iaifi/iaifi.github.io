type: postdoc
title: NTU AI-for-X Postdoctoral Fellowship in Epistemic Robot Learning
employer: Nanyang Technological University Singapore
post-date: 2025-09-21
deadline:
expire: 2025-10-21
link: https://iaifi.org/job-board.html#ntu-ai-for-x-postdoctoral-fellowship-in-epistemic-robot-learning
details: "​We are seeking a highly motivated candidate to apply for the NTU AI-for-X Postdoctoral Fellowship program. The fellow will join the College of Computing and Data Science, Nanyang Technological University Singapore, to work with Assistant Professor Yoonchang Sung and Assistant Professor Siu Lun Chau on the emerging area of Epistemic Robot Learning.<br><br>Project Overview<br><br>One crucial goal in robot learning is to train a policy model using large amounts of simulated, synthetic, realworld, or human data during the training phase, with the hope that it exhibits strong generalization capabilities to unseen, novel tasks at deployment. However, it remains unclear how far a trained model can generalize and whether a given task at deployment can be handled zero-shot or requires additional data for fine-tuning. Recent advances in statistical theory allow for representing and quantifying epistemic uncertainty, providing a way to reason about a model’s ignorance. This project aims to explore opportunities for leveraging epistemic uncertainty in robot learning to enable informed decision-making at deployment, thereby fundamentally enhancing the generalization and adaptability of robot foundation models.<br><br>Specifically, we propose to study three promising research thrusts:<br><br>1. Epistemic Uncertainty Quantification for Robot Learning<br>• A robot policy model is a large neural network that takes observations and human language commands as input and outputs actions. A key question is whether existing methods for epistemic uncertainty quantification—developed in the precise and imprecise probabilistic machine learning literature—are sufficient to capture the full complexity of robotic observations and language commands. If not, how might we design new frameworks tailored specifically for robotic systems?<br><br>Out-of-distribution Detection for Robotic Tasks<br>• Once epistemic uncertainty can be reliably quantified, a natural next step is to leverage it for out-ofdistribution (OOD) detection in robotic tasks. Effective OOD detection enables them to recognise when their learned knowledge and policies may no longer apply, so that they can trigger fallback strategies. Developing principled methods for OOD detection grounded in epistemic uncertainty is therefore critical for ensuring the safety, reliability, and adaptability of robot behaviours.<br><br>3. Human-in-the-loop Robotics through Deferral Learning • One important fallback strategy in OOD scenarios is to seek additional input from humans. This naturally connects to the framework of learning to defer, a subfield of rejection learning. The goal is not only to detect when the robot lacks sufficient confidence to act, but also to determine the most appropriate response in such cases—whether that means consulting a specific human expert, coordinating with fellow robots, or abstaining altogether when the task involves irreducible randomness. <br><br>What we look for<br>We are seeking highly self-motivated and passionate applicants who have a PhD in robotics, artificial intelligence, or machine learning, with strong publications in these fields. A background in robot learning and experience with real-robot experiments is strongly preferred. Knowledge in statistical methods for uncertainty quantification is not necessary, but highly desirable.<br><br>How to Apply?<br>If you are interested in this research direction, we encourage you to explore the work of Prof. Yoonchang Sung and Prof. Siu Lun Chau. To apply, please complete the application form at the link below. We will review submissions carefully and contact shortlisted candidates, and support your fellowship application.<br><br>https://forms.gle/erQSoAGptPo9e7ENA<br><br>We look forward to reading your application."
