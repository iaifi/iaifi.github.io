type: industry
title: Research Scientist Positions (Verification, Robustness)
employer: Safe Intelligence, London, England
post-date: 2024-12-15
deadline:
expire: 2025-01-16
link: http://www.safeintelligence.ai/
details: "Safe Intelligence is a deep-tech, venture-backed spin-out from Imperial College London building solutions to formally verify the correctness of ML models and improve their robustness against vulnerabilities. Our mission is to develop state-of-the-art research and products that make AI safe and secure for society as a whole.<br><br>We seek outstanding research scientists who share our passion for reliable AI to enable ML adoption in society-critical applications, including autonomous transportation, finance, robotics, medical imaging, and edge computing.<br><br>As a Research Scientist, you will conduct research aligning with the company mission, particularly on ML verification technology and certified learning. Safe Intelligence Research Scientists regularly share their results with the broader community by publishing in top conferences, and similar contributions will be welcomed. We are also passionate about enabling users to deploy ML models safely. A successful Research Scientist will also occasionally interact with users to capture requirements, share capabilities, and feed these to the product team for future iterations.<br><br>Joining Safe Intelligence is an opportunity to shape the emerging AI revolution by making it safer and more reliable for everyone.<br><br>Responsibilities:<br><br>As a Safe Intelligence Research Scientist, you will:<br>-Develop research on state-of-the-art methods in ML verification and robust learning, also in collaboration with others on the team and the wider community.<br>-Contribute to mapping out and planning the key research objectives for the company based on existing and emerging product capabilities and strategic objectives.<br>-Contribute to establishing a culture of high organisational performance.<br><br>Technical Requirements:<br>-Advanced knowledge in deep learning, verification for machine learning, or certified learning.<br>-Solid experience in training NNs or DTs.<br>-Solid experience in programming, including Python, particularly in the context of large codebases.<br>-Good communication skills.<br>-The ability to collaborate effectively across multiple functional teams.<br><br>As a team, we are:<br>-Passionate about delivering solutions to make AI safer for customers and society.<br>-Deeply technical and constantly in a state of learning.<br>-Committed to communicating clearly and efficiently to several audiences, including developers, clients, researchers, partners, and executives.<br>-Fearless in getting 'hands-on' with technology and execution.<br>-Comfortable with ambiguity with a drive for clarity.<br>-Honest, straightforward, and caring about each other’s well-being.<br><br>Benefits:<br><br>Competitive compensation. Safe Intelligence provides competitive compensation based on role and candidate experience. We are committed to discussing career progress, and the overall package will always be entirely transparent.<br><br>In addition, company benefits for all roles include:<br>-Stock option benefits.<br>-Mentoring, learning, and development allowance.<br>-Regular team social and work events.<br>-Flexible and generous holidays. We work hard and encourage everyone to take time off to recharge and enjoy other aspects of our lives.<br><br>Qualifications:<br><br>Minimum qualifications:<br>-Defended or about to defend a graduate degree in ML verification or ML robustness.<br>-Evidence of top academic publications.<br><br>Preferred qualifications:<br>-Experience in verification or advanced ML environment.<br>-Experience with complex codebases.<br>-Excellent communication, problem-solving, and judgement skills.<br>-Ability to create effective relationships and collaborate internally and externally effectively.<br>-Excellent analytical capabilities.<br><br>Location & Office Culture:<br><br>Safe Intelligence is based in London, UK, and we’re focused on building the initial team here. We highly value the ability to work flexibly and remotely at times, but we also have a strong belief that regular in-office interactions make for a much more fulfilling and productive work experience.<br><br>Our company culture combines optimism for the future (hard problems can be solved with the right effort), speed of iteration (the best ideas come from many ideas tested), and rigour in what matters (correctness and precision are critical for safety).<br><br>Application:<br><br>Please send CV and a short statement of your interest in the position to:<br><br>join@safeintelligence.ai<br>http://www.safeintelligence.ai<br><br>Come and join us to add your skills and passion to the future of Safe Artificial Intelligence!"
