type: paper
iaifi-thrust: F
title: "Overcoming the Spectral Bias of Neural Value Approximation"
authors: Ge Yang, Anurag Ajay, Pulkit Agrawal
abstract: Value approximation using deep neural networks is at the heart of off-policy deep reinforcement learning, and is often the primary module that provides learning signals to the rest of the algorithm.  While multi-layer perceptron networks are universal function approximators, recent works in neural kernel regression suggest the presence of a \textit{spectral bias}, where fitting high-frequency components of the value function requires exponentially more gradient update steps than the low-frequency ones. In this work, we re-examine off-policy reinforcement learning through the lens of kernel regression and propose to overcome such bias via a composite neural tangent kernel. With just a single line-change, our approach, the Fourier feature networks (FFN) produce state-of-the-art performance on challenging continuous control domains with only a fraction of the compute. Faster convergence and better off-policy stability also make it possible to remove the target network without suffering catastrophic divergences, which further reduces TD(0)'s estimation bias on a few tasks. Code and analysis available at https://geyang.github.io/ffn.
arxiv: 2206.04672
journal: ICLR 2022 Conference Proceedings
doi: https://openreview.net/forum?id=vIC-xLFuM6
nsf-par:
code: 
publication-date: 2021-09-28
bib-tex: |
  @misc{yang2022overcomingspectralbiasneural,
      title={Overcoming the Spectral Bias of Neural Value Approximation},
      author={Ge Yang and Anurag Ajay and Pulkit Agrawal},
      year={2022},
      eprint={2206.04672},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.04672},
  }
