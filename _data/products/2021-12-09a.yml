type: paper
iaifi-thrust: F
title: "Neural Descriptor Fields: SE(3) Equivariant Object Representations for Manipulation"
authors: Anthony Simeonov, Yilun Du, Andrea Tagliasacchi, Joshua B. Tenenbaum, Alberto Rodriguez, Pulkit Agrawal, Vincent Sitzmann
abstract: We present Neural Descriptor Fields (NDFs), an object representation that encodes both points and relative poses between an object and a target (such as a robot gripper or a rack used for hanging) via category-level descriptors. We employ this representation for object manipulation, where given a task demonstration, we want to repeat the same task on a new object instance from the same category. We propose to achieve this objective by searching (via optimization) for the pose whose descriptor matches that observed in the demonstration. NDFs are conveniently trained in a self-supervised fashion via a 3D auto-encoding task that does not rely on expert-labeled keypoints. Further, NDFs are SE(3)-equivariant, guaranteeing performance that generalizes across all possible 3D object translations and rotations. We demonstrate learning of manipulation tasks from few (5-10) demonstrations both in simulation and on a real robot. Our performance generalizes across both object instances and 6-DoF object poses, and significantly outperforms a recent baseline that relies on 2D descriptors. 
arxiv: 2112.05124
journal: International Conference on Robotics and Automation 2022
doi: https://doi.org/10.48550/arXiv.2112.05124
nsf-par:
code: https://yilundu.github.io/ndf/
publication-date: 2022-05-27
bib-tex: |
  @misc{simeonov2021neuraldescriptorfieldsse3equivariant,
      title={Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation},
      author={Anthony Simeonov and Yilun Du and Andrea Tagliasacchi and Joshua B. Tenenbaum and Alberto Rodriguez and Pulkit Agrawal and Vincent Sitzmann},
      year={2021},
      eprint={2112.05124},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2112.05124},
  }
