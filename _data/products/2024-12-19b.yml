type: paper
iaifi-thrust: F
arxiv-date: 2024-12-19
title: "Data for Mathematical Copilots: Better Ways of Presenting Proofs for Machine Learning"
authors: "Simon Frieder, Jonas Bayer, Katherine M. Collins, Julius Berner, Jacob Loader, András Juhász, Fabian Ruehle, Sean Welleck, Gabriel Poesia, Ryan-Rhys Griffiths, Adrian Weller, Anirudh Goyal, Thomas Lukasiewicz, Timothy Gowers"
abstract: "The suite of datasets commonly used to train and evaluate the mathematical capabilities of AI-based mathematical copilots (primarily large language models) exhibit several shortcomings. These limitations include a restricted scope of mathematical complexity, typically not exceeding lower undergraduate-level mathematics, binary rating protocols and other issues, which makes comprehensive proof-based evaluation suites difficult. We systematically explore these limitations and contend that enhancing the capabilities of large language models, or any forthcoming advancements in AI-based mathematical assistants (copilots or 'thought partners'), necessitates a paradigm shift in the design of mathematical datasets and the evaluation criteria of mathematical ability: It is necessary to move away from result-based datasets (theorem statement to theorem proof) and convert the rich facets of mathematical research practice to data LLMs can train on. Examples of these are mathematical workflows (sequences of atomic, potentially subfield-dependent tasks that are often performed when creating new mathematics), which are an important part of the proof-discovery process. Additionally, we advocate for mathematical dataset developers to consider the concept of 'motivated proof', introduced by G. Pólya in 1949, which can serve as a blueprint for datasets that offer a better proof learning signal, alleviating some of the mentioned limitations. Lastly, we introduce math datasheets for datasets, extending the general, dataset-agnostic variants of datasheets: We provide a questionnaire designed specifically for math datasets that we urge dataset creators to include with their datasets. This will make creators aware of potential limitations of their datasets while at the same time making it easy for readers to assess it from the point of view of training and evaluating mathematical copilots."
arxiv: "2412.15184"
journal:
doi:
nsf-par:
code:
publication-date:
bib-tex: |
  @article{frieder2024datamathematicalcopilotsbetter,
      title={Data for Mathematical Copilots: Better Ways of Presenting Proofs for Machine Learning},
      author={Simon Frieder and Jonas Bayer and Katherine M. Collins and Julius Berner and Jacob Loader and András Juhász and Fabian Ruehle and Sean Welleck and Gabriel Poesia and Ryan-Rhys Griffiths and Adrian Weller and Anirudh Goyal and Thomas Lukasiewicz and Timothy Gowers},
      year={2024},
      eprint={2412.15184},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.15184},
  }
