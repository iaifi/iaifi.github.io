type: paper
iaifi-thrust: A
title: "Maven: A Multimodal Foundation Model for Supernova Science"
authors: "Gemma Zhang, Thomas Helfer, Alexander T. Gagliano, Siddharth Mishra-Sharma, V. Ashley Villar"
abstract: "A common setting in astronomy is the availability of a small number of high-quality observations, and larger amounts of either lower-quality observations or synthetic data from simplified models. Time-domain astrophysics is a canonical example of this imbalance, with the number of supernovae observed photometrically outpacing the number observed spectroscopically by multiple orders of magnitude. At the same time, no data-driven models exist to understand these photometric and spectroscopic observables in a common context. Contrastive learning objectives, which have grown in popularity for aligning distinct data modalities in a shared embedding space, provide a potential solution to extract information from these modalities. We present Maven, the first foundation model for supernova science. To construct Maven, we first pre-train our model to align photometry and spectroscopy from 0.5M synthetic supernovae using a constrastive objective. We then fine-tune the model on 4,702 observed supernovae from the Zwicky Transient Facility. Maven reaches state-of-the-art performance on both classification and redshift estimation, despite the embeddings not being explicitly optimized for these tasks. Through ablation studies, we show that pre-training with synthetic data improves overall performance. In the upcoming era of the Vera C. Rubin Observatory, Maven serves as a Rosetta Stone for leveraging large, unlabeled and multimodal time-domain datasets."
arxiv: "2408.16829"
journal: "Machine Learning Science and Tehnology, Volume , Number 4, 2024"
doi: "https://doi.org/10.1088/2632-2153/ad990d"
nsf-par:
code: "https://github.com/ThomasHelfer/multimodal-supernovae"
publication-date: 2024-12-19
bib-tex: |
  @article{Zhang_2024,
    doi = {10.1088/2632-2153/ad990d},
    url = {https://dx.doi.org/10.1088/2632-2153/ad990d},
    year = {2024},
    month = {dec},
    publisher = {IOP Publishing},
    volume = {5},
    number = {4},
    pages = {045069},
    author = {Zhang, Gemma and Helfer, Thomas and Gagliano, Alexander T and Mishra-Sharma, Siddharth and Ashley Villar, V},
    title = {Maven: a multimodal foundation model for supernova science},
    journal = {Machine Learning: Science and Technology},
    abstract = {A common setting in astronomy is the availability of a small number of high-quality observations, and larger amounts of either lower-quality observations or synthetic data from simplified models. Time-domain astrophysics is a canonical example of this imbalance, with the number of supernovae observed photometrically outpacing the number observed spectroscopically by multiple orders of magnitude. At the same time, no data-driven models exist to understand these photometric and spectroscopic observables in a common context. Contrastive learning objectives, which have grown in popularity for aligning distinct data modalities in a shared embedding space, provide a potential solution to extract information from these modalities. We present Maven, the first foundation model for supernova science. To construct Maven, we first pre-train our model to align photometry and spectroscopy from 0.5‚ÄâM synthetic supernovae using a contrastive objective. We then fine-tune the model on 4702 observed supernovae from the Zwicky transient facility. Maven reaches state-of-the-art performance on both classification and redshift estimation, despite the embeddings not being explicitly optimized for these tasks. Through ablation studies, we show that pre-training with synthetic data improves overall performance. In the upcoming era of the Vera C. Rubin observatory, Maven will serve as a valuable tool for leveraging large, unlabeled and multimodal time-domain datasets.}
  }
